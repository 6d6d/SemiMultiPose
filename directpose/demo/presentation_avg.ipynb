{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import numpy as np\n",
    "import matplotlib.colorbar as colorbar\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from maskrcnn_benchmark.utils import cv2_util\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# this makes our figures bigger\n",
    "pylab.rcParams['figure.figsize'] = 20*1.5, 12*1.5\n",
    "\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.structures.keypoint import keypoints_to_heat_map\n",
    "from maskrcnn_benchmark.modeling.roi_heads.keypoint_head.loss import project_keypoints_to_heatmap\n",
    "from predictor import COCODemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(img_path):\n",
    "    \"\"\"\n",
    "    Given an url of an image, downloads the image and\n",
    "    returns a PIL image\n",
    "    \"\"\"\n",
    "    \n",
    "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    # convert to BGR format\n",
    "    image = np.array(pil_image)[:, :, [2, 1, 0]]\n",
    "    return image\n",
    "\n",
    "def load_video(video_path,frame_id=[0]):\n",
    "    \"\"\"\n",
    "    Given an url of an image, downloads the image and\n",
    "    returns a PIL image\n",
    "    \"\"\"\n",
    "    \n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    if frame_id is None:\n",
    "        nframes = int(video_clip.fps * video_clip.duration)\n",
    "        frame_id = range(nframes)\n",
    "    images = []\n",
    "    for i in frame_id:\n",
    "        image = video_clip.get_frame(i/video_clip.fps)\n",
    "        # convert to BGR format\n",
    "        image = np.array(image)[:, :, [2, 1, 0]]\n",
    "        images += [image]\n",
    "    video_clip.close()\n",
    "    \n",
    "    return images\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "# define vectorized sigmoid\n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "# num keypoints per animal, heatmap\n",
    "def calculate_peaks(numparts, heatmap_avg):\n",
    "    score = np.ones((numparts,)) * 0.000001\n",
    "    all_peaks = []\n",
    "    peak_counter = 0\n",
    "    if len(score) < numparts:\n",
    "        score = score[:numparts]\n",
    "        print(\"score\", score)\n",
    "        ##logger.ERROR(‘Not enough scores provided for number of parts’)\n",
    "        # return\n",
    "    # threshold_detection = params[‘thre1’]\n",
    "    # tic_localmax=time.time()\n",
    "    for part in range(numparts):\n",
    "        map_ori = heatmap_avg[part, :, :]\n",
    "        map = map_ori\n",
    "        map_left = np.zeros(map.shape)\n",
    "        map_left[1:, :] = map[:-1, :]\n",
    "        map_right = np.zeros(map.shape)\n",
    "        map_right[:-1, :] = map[1:, :]\n",
    "        map_up = np.zeros(map.shape)\n",
    "        map_up[:, 1:] = map[:, :-1]\n",
    "        map_down = np.zeros(map.shape)\n",
    "        map_down[:, :-1] = map[:, 1:]\n",
    "        #peaks_binary = np.logical_and(np.logical_and(np.logical_and(map >= map_left, map >= map_right),\n",
    "                                                     #np.logical_and(map >= map_up, map >= map_down)), map > score[part])\n",
    "        peaks_binary = (sigmoid_v(map_ori) > .2)\n",
    "        #print(\"pb shap\", np.shape(peaks_binary))\n",
    "        peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]))  # note reverse\n",
    "        peaks_with_score_and_id = [x + (map_ori[x[1], x[0]], i + peak_counter,) for i, x in\n",
    "                                   enumerate(peaks)]  # if x[0]>0 and x[1]>0 ]\n",
    "        all_peaks.append(peaks_with_score_and_id)\n",
    "        peak_counter += len(peaks)\n",
    "    return all_peaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'text.latex.preamble': ['\\\\usepackage{gensymb}'],\n",
    "    'image.origin': 'lower',\n",
    "    'image.interpolation': 'nearest',\n",
    "    'image.cmap': 'jet',\n",
    "    'axes.grid': False,\n",
    "    'savefig.dpi': 150,  # to adjust notebook inline plot size\n",
    "    'axes.labelsize': 10, # fontsize for x and y labels (was 10)\n",
    "    'axes.titlesize': 12,\n",
    "    'font.size': 12, # was 10\n",
    "    'legend.fontsize': 10, # was 10\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    #'text.usetex': True,\n",
    "    'figure.figsize': [3.39, 2.10],\n",
    "    'font.family': 'serif',\n",
    "}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_keypoints(image, predictions):\n",
    "        #keypoints = predictions.get_field(\"keypoints\")\n",
    "        kps = predictions#keypoints.keypoints\n",
    "        scores = kps.new_ones((kps.size(0), kps.size(1)))\n",
    "        kps = torch.cat((kps[:, :, 0:2], scores[:, :, None]), dim=2).numpy()\n",
    "        for region in kps:\n",
    "            kfun = BeeKeypoints\n",
    "            image = vis_keypoints_others(\n",
    "                    image,\n",
    "                    region.transpose((1, 0)),\n",
    "                    kp_thresh=0,\n",
    "                    kfun=kfun)\n",
    "                \n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.structures.image_list import to_image_list\n",
    "from maskrcnn_benchmark.modeling.roi_heads.mask_head.inference import Masker\n",
    "from maskrcnn_benchmark import layers as L\n",
    "from maskrcnn_benchmark.utils import cv2_util\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from maskrcnn_benchmark.structures.keypoint import PersonKeypoints, BeeKeypoints, FlyKeypoints\n",
    "\n",
    "\n",
    "def vis_keypoints_others(img, kps, kp_thresh=2, alpha=0.7, kfun=PersonKeypoints):\n",
    "    \"\"\"Visualizes keypoints (adapted from vis_one_image).\n",
    "    kps has shape (4, #keypoints) where 4 rows are (x, y, logit, prob).\n",
    "    \"\"\"\n",
    "    img = img.copy()\n",
    "    dataset_keypoints = kfun.NAMES\n",
    "    kp_lines = kfun.CONNECTIONS\n",
    "\n",
    "    # Convert from plt 0-1 RGBA colors to 0-255 BGR colors for opencv.\n",
    "    cmap = plt.get_cmap('rainbow')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]\n",
    "    colors = [(c[2] * 255, c[1] * 255, c[0] * 255) for c in colors]\n",
    "\n",
    "    # Perform the drawing on a copy of the image, to allow for blending.\n",
    "    kp_mask = np.copy(img)\n",
    "    \n",
    "    # Draw the keypoints.\n",
    "    for l in [0]:#range(len(kp_lines)):\n",
    "        i1 = kp_lines[l][0]\n",
    "        i2 = kp_lines[l][1]\n",
    "        p1 = kps[0, i1], kps[1, i1]\n",
    "        p2 = kps[0, i2], kps[1, i2]\n",
    "        #if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:\n",
    "         #   cv2.line(\n",
    "          #      kp_mask, p1, p2,\n",
    "           #     color=colors[l], thickness=2, lineType=cv2.LINE_AA)\n",
    "        if kps[2, i1] > kp_thresh:\n",
    "            cv2.circle(\n",
    "                kp_mask, p1,\n",
    "                radius=16, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)\n",
    "        #if kps[2, i2] > kp_thresh:\n",
    "         #   cv2.circle(\n",
    "          #      kp_mask, p2,\n",
    "           #     radius=16, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Blend the keypoints.\n",
    "    return cv2.addWeighted(img, 1.0 - alpha, kp_mask, alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = 'bee_test.png'\n",
    "#image = load(test_file)\n",
    "base = \"../tools/datasets/bee/train/\"\n",
    "test_files = [\"017062230800.jpg\", \"017062121664.jpg\", \"017062254800.jpg\", \"017062312000.jpg\", \"017062322800.jpg\", \"001706229257.jpg\", \"017062315600.jpg\",\n",
    "             \"001706237000.jpg\", \"017062251200.jpg\", \"017062314400.jpg\"]\n",
    "test_images = []\n",
    "for file in test_files:\n",
    "    test_images.append(load(base + file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "li:  <maskrcnn_benchmark.structures.image_list.ImageList object at 0x2ac79d5941d0>\n",
      "now prop\n",
      "[BoxList(num_boxes=95, image_width=1422, image_height=800, mode=xyxy)]\n",
      "None\n",
      "R\n",
      "T\n",
      "raw res:\n",
      "[BoxList(num_boxes=95, image_width=1422, image_height=800, mode=xyxy)]\n",
      "FIELDS:\n",
      "predictions BoxList(num_boxes=95, image_width=2560, image_height=1440, mode=xyxy)\n",
      "top preds BoxList(num_boxes=12, image_width=2560, image_height=1440, mode=xyxy)\n",
      "DONE COMPUTE\n",
      "[[[151 157 170]\n",
      "  [151 157 170]\n",
      "  [150 156 169]\n",
      "  ...\n",
      "  [136 158 170]\n",
      "  [136 158 170]\n",
      "  [136 158 170]]\n",
      "\n",
      " [[152 158 171]\n",
      "  [152 158 171]\n",
      "  [152 158 171]\n",
      "  ...\n",
      "  [136 158 170]\n",
      "  [136 158 170]\n",
      "  [136 158 170]]\n",
      "\n",
      " [[152 158 171]\n",
      "  [153 159 172]\n",
      "  [152 158 171]\n",
      "  ...\n",
      "  [136 158 170]\n",
      "  [136 158 170]\n",
      "  [136 158 170]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 60  65  66]\n",
      "  [ 63  68  69]\n",
      "  [ 62  67  68]\n",
      "  ...\n",
      "  [ 67  69  77]\n",
      "  [ 71  73  81]\n",
      "  [ 74  76  84]]\n",
      "\n",
      " [[ 61  66  67]\n",
      "  [ 63  68  69]\n",
      "  [ 63  68  69]\n",
      "  ...\n",
      "  [ 71  73  81]\n",
      "  [ 71  73  81]\n",
      "  [ 72  74  82]]\n",
      "\n",
      " [[ 62  67  68]\n",
      "  [ 64  69  70]\n",
      "  [ 64  69  70]\n",
      "  ...\n",
      "  [ 69  71  79]\n",
      "  [ 65  67  75]\n",
      "  [ 61  63  71]]]\n"
     ]
    }
   ],
   "source": [
    "#big plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "pad = 5\n",
    "k=10\n",
    "#print(\"test ig: \", test_images)\n",
    "#print(\"test files: \", test_image_files)\n",
    "rows = [\"Heatmap Loss\", \"Original DP Loss\", \"Combo Loss\", \"Combo OG\"]#\"DP Predictions\", \"Combined Heatmap\", \"Combined Pred\"]\n",
    "cols = [\"HM Markers\", \"DP Marker\", \"DP Boxes\"]\n",
    "data_size = \"250\"\n",
    "version = \"0\"\n",
    "#loss = \"combined_from_standard_nw\"\n",
    "loss = \"standard\"\n",
    "\n",
    "#fig, axes = plt.subplots(10,3,figsize=(40,54),constrained_layout=True,gridspec_kw = {'wspace':.15, 'hspace':.15})\n",
    "#fig.subplots_adjust(wspace=.15, hspace=.000001)\n",
    "\n",
    "#title = 'Standard 5000 epochs'\n",
    "#fig.suptitle(title, y=.92)\n",
    "\n",
    "config_file = \"/home/bsb2144/directpose/configs/fcos/fcos_kps_ms_training_R_50_FPN_1x.yaml\"\n",
    "\n",
    "cfg.merge_from_file(\"/home/bsb2144/directpose/configs/fcos/fcos_kps_ms_training_R_50_FPN_1x.yaml\")\n",
    "cfg.merge_from_list(['DATALOADER.NUM_WORKERS', '2', \\\n",
    "                     'DATATYPE', 'bee', \\\n",
    "                     'OUTPUT_DIR', 'training_dir/' + data_size + '/' + loss +'/fcos_kps_ms_training_R_50_FPN_1x_bee1', \\\n",
    "                     'MODEL.WEIGHT', '/home/bsb2144/directpose/tools/training_dir/' + data_size + '/'+ loss +'/fcos_kps_ms_training_R_50_FPN_1x_bee/model_0005000.pth',\\\n",
    "                     'DATASETS.TEST', \"('bee_val_cocostyle',)\",\\\n",
    "                     'DATASETS.TRAIN', \"('bee_train_cocostyle', )\",\\\n",
    "                    ])\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "            cfg,\n",
    "            min_image_size=800,\n",
    "            confidence_threshold=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "image = load(base+test_files[1])\n",
    "predictions, tps, hm_res, stride, hms, targets, c_loss = coco_demo.run_on_opencv_image(image)\n",
    "\n",
    "hms_tensor = hms.cpu().data.numpy() \n",
    "data_temp = gaussian_filter(sigmoid_v(hms_tensor[0][0]), sigma=1.3)\n",
    "scale_factor = sigmoid_v(hms_tensor[0][0]).max()/data_temp.max()\n",
    "\n",
    "print(\"DONE COMPUTE\")\n",
    "print(predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['keypoints', 'scores', 'labels']\n",
      "Keypoints(num_instances=12, image_width=2560, image_height=1440)\n",
      "hey [1956.143798828125, 666.973876953125]\n",
      "[[1.9561438e+03 9.4592889e+02 1.0000000e+00]\n",
      " [2.0503552e+03 7.1985370e+02 1.0000000e+00]\n",
      " [2.0163286e+03 7.9410480e+02 1.0000000e+00]\n",
      " [2.1041252e+03 6.9930377e+02 1.0000000e+00]\n",
      " [2.0305597e+03 6.6697388e+02 1.0000000e+00]]\n",
      "1956.1438 945.9289\n"
     ]
    }
   ],
   "source": [
    "print(tps.fields())\n",
    "print(tps.get_field(\"keypoints\"))\n",
    "#print(tps.get_field(\"keypoints\").keypoints)\n",
    "#print(tps.get_field(\"labels\"))\n",
    "#print(tps.get_field(\"scores\"))\n",
    "#print(tps.bbox)\n",
    "print(\"hey\", tps.bbox[0][:2].tolist())\n",
    "kps = tps.get_field(\"keypoints\").keypoints\n",
    "scores = kps.new_ones((kps.size(0), kps.size(1)))\n",
    "kps = torch.cat((kps[:, :, 0:2], scores[:, :, None]), dim=2).numpy()\n",
    "print(kps[0])\n",
    "print(kps[0].transpose((1, 0))[0, 0], kps[0].transpose((1, 0))[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 of 8: 100/0/standard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#big plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "pad = 5\n",
    "k=10\n",
    "#print(\"test ig: \", test_images)\n",
    "#print(\"test files: \", test_image_files)\n",
    "rows = [\"Heatmap Loss\", \"Original DP Loss\", \"Combo Loss\", \"Combo OG\"]#\"DP Predictions\", \"Combined Heatmap\", \"Combined Pred\"]\n",
    "cols = [\"HM Markers\", \"DP Marker\", \"DP Boxes\"]\n",
    "data_size = \"250\"\n",
    "version = \"0\"\n",
    "#loss = \"combined_from_standard_nw\"\n",
    "loss = \"standard\"\n",
    "\n",
    "fig, axes = plt.subplots(10,3,figsize=(40,54),constrained_layout=True,gridspec_kw = {'wspace':.15, 'hspace':.15})\n",
    "fig.subplots_adjust(wspace=.15, hspace=.000001)\n",
    "\n",
    "title = 'Standard 5000 epochs'\n",
    "fig.suptitle(title, y=.92)\n",
    "\n",
    "config_file = \"/home/bsb2144/directpose/configs/fcos/fcos_kps_ms_training_R_50_FPN_1x.yaml\"\n",
    "\n",
    "cfg.merge_from_file(\"/home/bsb2144/directpose/configs/fcos/fcos_kps_ms_training_R_50_FPN_1x.yaml\")\n",
    "cfg.merge_from_list(['DATALOADER.NUM_WORKERS', '2', \\\n",
    "                     'DATATYPE', 'bee', \\\n",
    "                     'OUTPUT_DIR', 'training_dir/' + data_size + '/' + loss +'/fcos_kps_ms_training_R_50_FPN_1x_bee1', \\\n",
    "                     'MODEL.WEIGHT', '/home/bsb2144/directpose/tools/training_dir/' + data_size + '/'+ loss +'/fcos_kps_ms_training_R_50_FPN_1x_bee/model_0005000.pth',\\\n",
    "                     'DATASETS.TEST', \"('bee_val_cocostyle',)\",\\\n",
    "                     'DATASETS.TRAIN', \"('bee_train_cocostyle', )\",\\\n",
    "                    ])\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "            cfg,\n",
    "            min_image_size=800,\n",
    "            confidence_threshold=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "for idx, image in enumerate(test_images):\n",
    "    #fig, axes = plt.subplots(1,3,figsize=(40,24),constrained_layout=True,gridspec_kw = {'wspace':.15, 'hspace':.15})\n",
    "    fig.subplots_adjust(wspace=.15, hspace=.000001)\n",
    "    predictions, tps, hm_res, stride, hms, targets, c_loss = coco_demo.run_on_opencv_image(image)\n",
    "    \n",
    "    hms_tensor = hms.cpu().data.numpy() \n",
    "    data_temp = gaussian_filter(sigmoid_v(hms_tensor[0][0]), sigma=1.3)\n",
    "    scale_factor = sigmoid_v(hms_tensor[0][0]).max()/data_temp.max()\n",
    "    peaks = calculate_peaks(1, (hms_tensor[0]))\n",
    "\n",
    "    hm_temp = torch.zeros(np.shape(peaks[0])[0], 5, 3)\n",
    "    for ind, row in enumerate(peaks[0]):\n",
    "        #print(float(row[0]))\n",
    "        hm_temp[ind][0][0] = float(row[0])*14.4\n",
    "        hm_temp[ind][0][1] = float(row[1])*14.222222222222222\n",
    "        hm_temp[ind][0][2] = sigmoid(float(row[2]))\n",
    "    #print(\"hm_temp\",hm_temp)\n",
    "\n",
    "    im = overlay_keypoints(image, hm_temp)\n",
    "            \n",
    "    base_file = 'bee_' + data_size + '_' + version \n",
    "            #if loss != \"heatmap\":\n",
    "             #   cv2.imwrite(base_file + \".png\", predictions[:, :, [2, 1, 0]])\n",
    "            #fig, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "            #if loss == \"heatmap\":\n",
    "                #axes[0][col].set_title('min {:.2f} max {:.2f}'.format(data_temp.min(), data_temp.max()))\n",
    "                #axes[0][col].set_title(\"Data Set \" + version)\n",
    "                #im = axes[0][col].imshow(data_temp, interpolation='none', vmin= data_temp.min(), vmax=data_temp.max())\n",
    "    img1 = im\n",
    "    #b,g,r = cv2.split(img2)       # get b,g,r\n",
    "    #im = cv2.merge([r,g,b])     # switch it to rgb\n",
    "    im = axes[idx][0].imshow(img1)\n",
    "    axes[idx][0].invert_yaxis()\n",
    "    plt.savefig(base_file + '_hm.png')\n",
    "                \n",
    "    img2 = overlay_keypoints(image,tps.get_field(\"keypoints\").keypoints)\n",
    "    #b,g,r = cv2.split(img2)       # get b,g,r\n",
    "    #img2 = cv2.merge([r,g,b])     # switch it to rgb\n",
    "    im = axes[idx][1].imshow(img2)\n",
    "    axes[idx][1].invert_yaxis()\n",
    "    plt.savefig(base_file + '_reg.png')\n",
    "    \n",
    "    img3 = predictions[:, :, [2, 1, 0]]\n",
    "    b,g,r = cv2.split(img3)       # get b,g,r\n",
    "    img3 = cv2.merge([r,g,b])     # switch it to rgb\n",
    "    im = axes[idx][2].imshow(img3)\n",
    "    axes[idx][2].invert_yaxis()\n",
    "    plt.savefig(base_file + '_reg.png')\n",
    "                \n",
    "    #for ax, row in zip(axes[0], rows):\n",
    "     #   ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "      #  xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "       # size='large', ha='right', va='center')\n",
    "\n",
    "    #fig.show()\n",
    "    #plt.pause(5)     \n",
    "            \n",
    "    for ax, col in zip(axes[0], cols):\n",
    "        ax.annotate(col, xy=(0.5, 1), xytext=(0, pad),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size='large', ha='center', va='baseline')\n",
    "\n",
    "#cbar = fig.colorbar(im, ax=axes.flat)\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(left=0.15, top=0.95, hspace=.000001)\n",
    "fig.subplots_adjust(wspace=.015, hspace=.000001)\n",
    "#cbar = fig.colorbar(im, ax=axes.flat)\n",
    "fig.savefig('std_5000'  +'.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#big plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "pad = 5\n",
    "k=10\n",
    "#print(\"test ig: \", test_images)\n",
    "#print(\"test files: \", test_image_files)\n",
    "rows = [\"Heatmap Loss\", \"Original DP Loss\", \"Combo Loss\", \"Combo OG\"]#\"DP Predictions\", \"Combined Heatmap\", \"Combined Pred\"]\n",
    "cols = [\"HM Markers\", \"DP Marker\", \"DP Boxes\"]\n",
    "data_size = \"250\"\n",
    "version = \"0\"\n",
    "#loss = \"combined_from_standard_nw\"\n",
    "loss = \"combined_from_standard_nw_nondup\"\n",
    "alphas = [\".0001\", \".001\", \".01\", \".1\", \".5\", \"1\"]\n",
    "\n",
    "for alpha in alphas:\n",
    "    fig, axes = plt.subplots(10,3,figsize=(40,54),constrained_layout=True,gridspec_kw = {'wspace':.15, 'hspace':.15})\n",
    "    fig.subplots_adjust(wspace=.15, hspace=.000001)\n",
    "\n",
    "    title = 'Standard 2500 Combined 2500: Alpha = ' + alpha\n",
    "    fig.suptitle(title, y=.92)\n",
    "\n",
    "    config_file = \"/home/bsb2144/directpose/configs/fcos/fcos_kps_ms_training_R_50_FPN_1x.yaml\"\n",
    "\n",
    "    cfg.merge_from_file(\"/home/bsb2144/directpose/configs/fcos/fcos_kps_ms_training_R_50_FPN_1x.yaml\")\n",
    "    cfg.merge_from_list(['DATALOADER.NUM_WORKERS', '2', \\\n",
    "                         'DATATYPE', 'bee', \\\n",
    "                         'OUTPUT_DIR', 'training_dir/' + data_size + '/' + loss +   '/' + alpha +'/avg/fcos_kps_ms_training_R_50_FPN_1x_bee1', \\\n",
    "                         'MODEL.WEIGHT', '/home/bsb2144/directpose/tools/training_dir/' + data_size + '/'+ loss +'/' + alpha +'/avg/fcos_kps_ms_training_R_50_FPN_1x_bee/model_0002500.pth',\\\n",
    "                         'DATASETS.TEST', \"('bee_val_cocostyle',)\",\\\n",
    "                         'DATASETS.TRAIN', \"('bee_train_cocostyle', )\",\\\n",
    "                        ])\n",
    "\n",
    "    coco_demo = COCODemo(\n",
    "                cfg,\n",
    "                min_image_size=800,\n",
    "                confidence_threshold=0.2,\n",
    "    )\n",
    "\n",
    "\n",
    "    for idx, image in enumerate(test_images):\n",
    "        #fig, axes = plt.subplots(1,3,figsize=(40,24),constrained_layout=True,gridspec_kw = {'wspace':.15, 'hspace':.15})\n",
    "        fig.subplots_adjust(wspace=.15, hspace=.000001)\n",
    "        predictions, tps, hm_res, stride, hms, targets, c_loss = coco_demo.run_on_opencv_image(image)\n",
    "\n",
    "        hms_tensor = hms.cpu().data.numpy() \n",
    "        data_temp = gaussian_filter(sigmoid_v(hms_tensor[0][0]), sigma=1.3)\n",
    "        scale_factor = sigmoid_v(hms_tensor[0][0]).max()/data_temp.max()\n",
    "        peaks = calculate_peaks(1, (hms_tensor[0]))\n",
    "\n",
    "        hm_temp = torch.zeros(np.shape(peaks[0])[0], 5, 3)\n",
    "        for ind, row in enumerate(peaks[0]):\n",
    "            #print(float(row[0]))\n",
    "            hm_temp[ind][0][0] = float(row[0])*14.4\n",
    "            hm_temp[ind][0][1] = float(row[1])*14.222222222222222\n",
    "            hm_temp[ind][0][2] = sigmoid(float(row[2]))\n",
    "        #print(\"hm_temp\",hm_temp)\n",
    "\n",
    "        im = overlay_keypoints(image, hm_temp)\n",
    "\n",
    "        base_file = 'bee_' + data_size + '_' + version \n",
    "                #if loss != \"heatmap\":\n",
    "                 #   cv2.imwrite(base_file + \".png\", predictions[:, :, [2, 1, 0]])\n",
    "                #fig, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "                #if loss == \"heatmap\":\n",
    "                    #axes[0][col].set_title('min {:.2f} max {:.2f}'.format(data_temp.min(), data_temp.max()))\n",
    "                    #axes[0][col].set_title(\"Data Set \" + version)\n",
    "                    #im = axes[0][col].imshow(data_temp, interpolation='none', vmin= data_temp.min(), vmax=data_temp.max())\n",
    "        img1 = im\n",
    "        #b,g,r = cv2.split(img2)       # get b,g,r\n",
    "        #im = cv2.merge([r,g,b])     # switch it to rgb\n",
    "        im = axes[idx][0].imshow(img1)\n",
    "        axes[idx][0].invert_yaxis()\n",
    "        plt.savefig(base_file + '_hm.png')\n",
    "\n",
    "        img2 = overlay_keypoints(image,tps.get_field(\"keypoints\").keypoints)\n",
    "        #b,g,r = cv2.split(img2)       # get b,g,r\n",
    "        #img2 = cv2.merge([r,g,b])     # switch it to rgb\n",
    "        im = axes[idx][1].imshow(img2)\n",
    "        axes[idx][1].invert_yaxis()\n",
    "        plt.savefig(base_file + '_reg.png')\n",
    "\n",
    "        img3 = predictions[:, :, [2, 1, 0]]\n",
    "        b,g,r = cv2.split(img3)       # get b,g,r\n",
    "        img3 = cv2.merge([r,g,b])     # switch it to rgb\n",
    "        im = axes[idx][2].imshow(img3)\n",
    "        axes[idx][2].invert_yaxis()\n",
    "        plt.savefig(base_file + '_reg.png')\n",
    "\n",
    "        #for ax, row in zip(axes[0], rows):\n",
    "         #   ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "          #  xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "           # size='large', ha='right', va='center')\n",
    "\n",
    "        #fig.show()\n",
    "        #plt.pause(5)     \n",
    "\n",
    "        for ax, col in zip(axes[0], cols):\n",
    "            ax.annotate(col, xy=(0.5, 1), xytext=(0, pad),\n",
    "                    xycoords='axes fraction', textcoords='offset points',\n",
    "                    size='large', ha='center', va='baseline')\n",
    "\n",
    "    #cbar = fig.colorbar(im, ax=axes.flat)\n",
    "    #fig.tight_layout()\n",
    "    #fig.subplots_adjust(left=0.15, top=0.95, hspace=.000001)\n",
    "    fig.subplots_adjust(wspace=.015, hspace=.000001)\n",
    "    #cbar = fig.colorbar(im, ax=axes.flat)\n",
    "    fig.savefig('std_avg_'+ alpha  +'.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
