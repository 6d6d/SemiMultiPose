{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import json\n",
    "import matplotlib\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import numpy as np\n",
    "import matplotlib.colorbar as colorbar\n",
    "import pickle\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from maskrcnn_benchmark.utils import cv2_util\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# this makes our figures bigger\n",
    "pylab.rcParams['figure.figsize'] = 20*1.5, 12*1.5\n",
    "\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from predictor import COCODemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(img_path):\n",
    "    \"\"\"\n",
    "    Given an url of an image, downloads the image and\n",
    "    returns a PIL image\n",
    "    \"\"\"\n",
    "    \n",
    "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    # convert to BGR format\n",
    "    image = np.array(pil_image)[:, :, [2, 1, 0]]\n",
    "    return image\n",
    "\n",
    "def load_video(video_path,frame_id=[0]):\n",
    "    \"\"\"\n",
    "    Given an url of an image, downloads the image and\n",
    "    returns a PIL image\n",
    "    \"\"\"\n",
    "    \n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    if frame_id is None:\n",
    "        nframes = int(video_clip.fps * video_clip.duration)\n",
    "        frame_id = range(nframes)\n",
    "    images = []\n",
    "    for i in frame_id:\n",
    "        image = video_clip.get_frame(i/video_clip.fps)\n",
    "        # convert to BGR format\n",
    "        image = np.array(image)[:, :, [2, 1, 0]]\n",
    "        images += [image]\n",
    "    video_clip.close()\n",
    "    \n",
    "    return images\n",
    "\n",
    "def imshow(img):\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.imshow(img[:, :, [2, 1, 0]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image directory\n",
    "base = \"../tools/datasets/bee/validation/\"\n",
    "\n",
    "# json file (just needs image names)\n",
    "base_val = \"../tools/datasets/bee/annotations/validation.json\"\n",
    "\n",
    "with open(base_val) as f:\n",
    "    data_an = json.load(f)\n",
    "\n",
    "test_files = []\n",
    "for p in data_an['images'][:]:\n",
    "    test_files.append(str(p['file_name']))\n",
    "\n",
    "test_images = []\n",
    "for file in test_files:\n",
    "    test_images.append(load(base + file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores predictions\n",
    "predictions = []\n",
    "\n",
    "# stores images\n",
    "predicted_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get predictions from model\n",
    "import matplotlib.gridspec as gridspec\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "model_weight = '/home/bsb2144/directpose/tools/training_dir/25/c_new/p2_standard/1/fcos_kps_ms_training_R_50_FPN_1x_bee/model_final.pth' \n",
    "config_file = \"/home/bsb2144/directpose/configs/fcos/fcos_kps_ms_training_R_50_FPN_1x.yaml\"\n",
    "\n",
    "cfg.merge_from_file(config_file)\n",
    "cfg.merge_from_list(['DATALOADER.NUM_WORKERS', '2', \\\n",
    "                     'DATATYPE', 'bee', \\\n",
    "                     'MODEL.WEIGHT', model_weight,\\\n",
    "                     'DATASETS.TEST', \"('bee_val_cocostyle',)\",\\\n",
    "                     'DATASETS.TRAIN', \"('bee_train_cocostyle', )\",\\\n",
    "                    ])\n",
    "\n",
    "coco_demo = COCODemo(\n",
    "            cfg,\n",
    "            min_image_size=800,\n",
    "            confidence_threshold=0.20,\n",
    ")\n",
    "for idx, image in enumerate(test_images):\n",
    "    predicted_image, prediction = coco_demo.run_on_opencv_image(image, include_predictions=True)\n",
    "    predicted_images.append(predicted_image)\n",
    "    predictions.append(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to json file\n",
    "out_dir = \"predictions.json\" \n",
    "with open(out_dir, 'wb') as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicted images to video\n",
    "save_file = 'prediction_video.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "dd1,dd2 = (predicted_images[0].shape[0]),(predicted_images[0].shape[1])\n",
    "out = cv2.VideoWriter(save_file, fourcc, 1.0, (dd2,dd1))\n",
    "\n",
    "for image in predicted_images:\n",
    "    out.write(image)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
